{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IdPzTRejTJpJ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import warnings                                  # `do not disturbe` mode\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style='whitegrid', palette='deep', font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "4e1tF_Q-TJpN",
    "outputId": "df8aecff-ac68-4695-f410-d37142b87245"
   },
   "outputs": [],
   "source": [
    "# Tensorflow imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Input, BatchNormalization, \\\n",
    "    multiply, concatenate, Flatten, Activation, dot\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# this is for making Graphviz work (plot_model needs GraphViz)\n",
    "from IPython.display import HTML\n",
    "from keras.utils.vis_utils import plot_model, model_to_dot\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "os.sys.path.append('..')\n",
    "from utils.model_utils import serialize_model\n",
    "from utils.model_utils import split_sequences_multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block to load file depending if you are in Colab or in Jupyter\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('Running on CoLab')\n",
    "    !wget --no-check-certificate \\\n",
    "        https://www.dropbox.com/s/qbn9y5ooqxipxki/single_feature.csv?dl=0 \\\n",
    "        -O /tmp/Features.csv\n",
    "        \n",
    "    data = pd.read_csv('/tmp/Features.csv', parse_dates=['Timestamp'], index_col='Timestamp')\n",
    "else:\n",
    "    path_of_file = '../Data/single_feature.csv'\n",
    "    data = pd.read_csv(path_of_file, parse_dates=['Timestamp'], index_col='Timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 648
    },
    "id": "GvDyWyQ6TJpb",
    "outputId": "2e46b3ea-0afd-4419-af1f-7685261d02be"
   },
   "outputs": [],
   "source": [
    "# The data is higly irregular so let's resample it to 10 min and take the mean\n",
    "resampled = data.resample('30Min').mean()\n",
    "resampled = resampled.fillna(resampled.bfill())\n",
    "# Now let's take only a slice of it\n",
    "\n",
    "init_date = '2019-03'\n",
    "train_end_date = '2019-10-25'\n",
    "end_date = '2019-04-20'\n",
    "#Separate Train and test\n",
    "train_data = resampled[init_date:end_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "3Vrc2QjbTJpe",
    "outputId": "3bfdb5a2-a697-481a-acd5-898bd0a7d408"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of Data 2448\n",
      "Lenght of Train 1958\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "train_ratio = 0.8\n",
    "train_len = int(train_ratio*len(train_data))\n",
    "scaler = MinMaxScaler()\n",
    "normalized_train = scaler.fit_transform(train_data)\n",
    "print('Lenght of Data {}'.format(len(normalized_train)))\n",
    "print('Lenght of Train {}'.format(train_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps = [32, 64, 128, 256]\n",
    "n_features = normalized_train.shape[-1]\n",
    "history_list = []\n",
    "model_list = []\n",
    "batches = [16,32,64,128]\n",
    "\n",
    "train_predictions_list = []\n",
    "test_predictions_list = []\n",
    "MAE_train = []\n",
    "MAE_test = []\n",
    "mae_overall_train_list = []\n",
    "mae_overall_test_list = []\n",
    "\n",
    "for timestep in n_timesteps:\n",
    "    for batch in batches:\n",
    "\n",
    "    train_X_lstm, train_y_lstm = split_sequences_multivariate(normalized_train[:train_len], n_steps=timestep)\n",
    "    test_X_lstm, test_y_lstm = split_sequences_multivariate(normalized_train[train_len:], n_steps=timestep)\n",
    "    #print('Training Shapes. X{}, y{} '.format(train_X_lstm.shape, train_y_lstm.shape))\n",
    "    #print('Testing Shapes. X{}, y{} '.format(test_X_lstm.shape, test_y_lstm.shape))\n",
    "\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units=128, input_shape=(n_timesteps, n_features),\n",
    "                                        return_sequences=True, dropout=0.2))\n",
    "    model.add(tf.keras.layers.LSTM(units=128, input_shape=(n_timesteps, n_features),\n",
    "                                        return_sequences=False, dropout=0.2))\n",
    "    #model_LSTM.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dense(n_features))\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=0.01)\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mae'])\n",
    "    \n",
    "    model_list.append(model)\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "    history = model.fit(train_X_lstm, train_y_lstm,\n",
    "                             validation_split=0.2, \n",
    "                             epochs=epochs, verbose=1,\n",
    "                             callbacks=[early_stop], \n",
    "                             batch_size=batch)\n",
    "\n",
    "    history_df.append(pd.DataFrame(history.history, columns=['mae', 'val_mae']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
